{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85408595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358a653e",
   "metadata": {},
   "source": [
    "First, In the webcam face detection we want to create a class FaceDetector which takes the cascade xml file as input in the **__init __**  method and a instantes called faceCascade as the Cascade Classifier, then the **detect** method which takes video frame , scalFactor, minNeighbors, minSize as the arguments and call the detectMultiScale and outputs the parameters of the rectangle (face in video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71376f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Face Detector class\n",
    "class FaceDetector:\n",
    "    def __init__(self, faceCascadePath):\n",
    "        \"\"\"\n",
    "        Calling the Cascade Classifier function in opencv to detect faces by taking the \n",
    "        haar cascade xml file as the argument (convert serialized xml file (classifier) into \n",
    "        deseralized classifier)\n",
    "        \"\"\"\n",
    "        self.faceCascade = cv2.CascadeClassifier(faceCascadePath)\n",
    "        \n",
    "    def detect(self, image, scaleFactor=1.2, minNeighbors=5, minSize=(30, 30)):\n",
    "        rects = self.faceCascade.detectMultiScale(image,\n",
    "                                                  scaleFactor=scaleFactor,\n",
    "                                                  minNeighbors=minNeighbors,\n",
    "                                                  minSize=minSize,\n",
    "                                                  flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        return rects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf457b3c",
   "metadata": {},
   "source": [
    "### Parameters used in the detectMultiScale function \n",
    "**scaleFactor**: How much the image size is reduced at each image scale. This value is used to create the scale pyramid in order to detect faces at multiple scales in the image (some faces may be closer to the foreground, and thus be larger; other faces may be smaller and in the background, thus the usage of varying scales). A value of 1.05 indicates that Jeremy is reducing the size of the image by 5% at each level in the pyramid.                                                                                      \n",
    "\n",
    "**minNeighbors**: How many neighbors each windo w should have for the area in the window to be considered a face. The cascade classifier will detect multiple windows around a face. This parameter controls how many rectangles (neighbors) need to be detected for the window to be labeled a face.\n",
    "\n",
    "**minSize**: A tuple of width and height (in pixels) indicating the minimum size of the window. Bounding boxes smaller than this size are ignored. It is a good idea to start with (30, 30) and fine-tune from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12954e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
    "    (h, w) = image.shape[:2]\n",
    "    dim = None\n",
    "    \n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    \n",
    "    if width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(r * w), height)\n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(r * h))\n",
    "        \n",
    "    resized = cv2.resize(image, dim, interpolation=inter)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917e463d",
   "metadata": {},
   "source": [
    "Here, we want to resize the video as per the convinence. For that we can create the resize function using OpenCV library which takes the video frame and the width to be resized as the parameters and outputs the resized video frame, we want the webcam should be opened. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d29fe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a object for Face Detector class\n",
    "fd = FaceDetector('cascade file/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "355e93d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing the video (webcam)\n",
    "webcam = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e38e86a",
   "metadata": {},
   "source": [
    "The video is represented as the multi frame(more images). So, we want to loop through this all frame to get the video and then we use our detect method in our faceDetector to detect the face in it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6b0513e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all the frames\n",
    "while True:\n",
    "    # read the frames(images) in the video and bool value which says True(grabbed) using read() function    \n",
    "    (grabbed, frame) = webcam.read()\n",
    "    \n",
    "    # Resize the video\n",
    "    frame = resize(frame, width=500)\n",
    "    # Convert RGB into Gray Scale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect the face in the video and gives back the face as the rectangle (x, y, w, h) \n",
    "    faceRects = fd.detect(frame, \n",
    "                          scaleFactor=1.1,\n",
    "                          minNeighbors=5, \n",
    "                          minSize=(30, 30))\n",
    "    # Coping the frames for further pre-processing\n",
    "    frameClone = frame.copy()\n",
    "    \n",
    "    # Create rectangle shape in the face \n",
    "    for (x, y, w, h) in faceRects:\n",
    "        cv2.rectangle(frameClone, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    \n",
    "    # Show the video \n",
    "    cv2.imshow(\"Faces\", frameClone)\n",
    "    \n",
    "    # To Close the webcam or video we it is enough\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break   \n",
    "\n",
    "# When everything is done, release the capture      \n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae7ee5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
